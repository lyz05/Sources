# -*- coding: utf-8 -*-
"""O2O最终版.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wDu3fBnsgOjzMKUFrjNlD58ayG9z5gsF

# 天池o2o优惠券使用预测比赛解析（进阶）

**赛题链接：**

[天池o2o优惠券使用预测](https://tianchi.aliyun.com/getStart/introduction.htm?spm=5176.100066.0.0.518433afBqXIKM&raceId=231593)

## 导入相关库
"""

# import libraries necessary for this project
import os, sys, pickle
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
 
from datetime import date
from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve
from sklearn.preprocessing import MinMaxScaler
 
import xgboost as xgb
import lightgbm as lgb

#设置工作目录
os.chdir("/content/drive/MyDrive/O2O")

"""## 导入数据"""

# keep_default_na=False 缺失值使用csv文件原本的null代替
dfoff = pd.read_csv('ccf_offline_stage1_train.csv',keep_default_na=False)
#dfon = pd.read_csv('ccf_online_stage1_train.csv',keep_default_na=False)
dftest = pd.read_csv('ccf_offline_stage1_test_revised.csv',keep_default_na=False)

dfoff.head(5)

"""## 特征提取

### 打折率 Discount_rate
"""

print('Discount_rate 类型：\n',dfoff['Discount_rate'].unique())

"""打折率分为 3 种情况：

- 'null' 表示没有打折

- [0,1] 表示折扣率

- x:y 表示满x减y

**处理方式：**

- 打折类型：getDiscountType()

- 折扣率：convertRate()

- 满多少：getDiscountMan()

- 减多少：getDiscountJian()
"""

# Convert Discount_rate and Distance
# 打折类型
def getDiscountType(row):
    if row == 'null':
        return 'null'
    elif ':' in row:
        return 1
    else:
        return 0

# 折扣率
def convertRate(row):
    if row == 'null':
        return 1.0
    elif ':' in row:
        rows = row.split(':')
        return 1.0 - float(rows[1])/float(rows[0])
    else:
        return float(row)

# 满多少
def getDiscountMan(row):
    if ':' in row:
        rows = row.split(':')
        return int(rows[0])
    else:
        return 0

# 减多少
def getDiscountJian(row):
    if ':' in row:
        rows = row.split(':')
        return int(rows[1])
    else:
        return 0
    
def processData(df):
    # convert discount_rate
    df['discount_type'] = df['Discount_rate'].apply(getDiscountType)
    df['discount_rate'] = df['Discount_rate'].apply(convertRate)
    df['discount_man'] = df['Discount_rate'].apply(getDiscountMan)
    df['discount_jian'] = df['Discount_rate'].apply(getDiscountJian)
    
    print(df['discount_rate'].unique())
    
    return df

dfoff = processData(dfoff)
dftest = processData(dftest)

dfoff.head(5)

"""### 距离 Distance"""

print('Distance 类型：',dfoff['Distance'].unique())

"""将距离 str 转为 int。"""

# convert distance
dfoff['distance'] = dfoff['Distance'].replace('null', -1).astype(int)
print(dfoff['distance'].unique())
dftest['distance'] = dftest['Distance'].replace('null', -1).astype(int)
print(dftest['distance'].unique())

dfoff.head(5)

"""### 领劵日期 Date_received

**关于领劵日期的特征：**

- weekday : {null, 1, 2, 3, 4, 5, 6, 7}

- weekday_type : {1, 0}（周六和周日为1，其他为0）

- Weekday_1 : {1, 0, 0, 0, 0, 0, 0}

- Weekday_2 : {0, 1, 0, 0, 0, 0, 0}

- Weekday_3 : {0, 0, 1, 0, 0, 0, 0}

- Weekday_4 : {0, 0, 0, 1, 0, 0, 0}

- Weekday_5 : {0, 0, 0, 0, 1, 0, 0}

- Weekday_6 : {0, 0, 0, 0, 0, 1, 0}

- Weekday_7 : {0, 0, 0, 0, 0, 0, 1}
"""

def getWeekday(row):
    if row == 'null':
        return row
    else:
        return date(int(row[0:4]), int(row[4:6]), int(row[6:8])).weekday() + 1 #返回当前日期是星期几

dfoff['weekday'] = dfoff['Date_received'].astype(str).apply(getWeekday)
dftest['weekday'] = dftest['Date_received'].astype(str).apply(getWeekday)

# weekday_type :  周六和周日为1，其他为0
dfoff['weekday_type'] = dfoff['weekday'].apply(lambda x: 1 if x in [6,7] else 0)
dftest['weekday_type'] = dftest['weekday'].apply(lambda x: 1 if x in [6,7] else 0)

# 改变 weekday 到 one-hot 编码 
weekdaycols = ['weekday_' + str(i) for i in range(1,8)]
#print(weekdaycols)

tmpdf = pd.get_dummies(dfoff['weekday'].replace('null', np.nan))
tmpdf.columns = weekdaycols
dfoff[weekdaycols] = tmpdf

tmpdf = pd.get_dummies(dftest['weekday'].replace('null', np.nan))
tmpdf.columns = weekdaycols
dftest[weekdaycols] = tmpdf

dfoff.head(5)

"""### 所有特征：

- discount_rate

- discount_type

- discount_man

- discount_jian

- distance

- weekday

- weekday_type

- weekday_1

- weekday_2

- weekday_3

- weekday_4

- weekday_5

- weekday_6

- weekday_7

## 标签标注

三种情况：

- Date_received == 'null'：表示没有领到优惠券，无需考虑，y = -1

- (Date_received != 'null') & (Date != 'null') & (Date - Date_received <= 15)：表示领取优惠券且在15天内使用，即正样本，y = 1

- (Date_received != 'null') & ((Date == 'null') | (Date - Date_received > 15))：表示领取优惠券未在在15天内使用，即负样本，y = 0

定义标签备注函数：
"""

def label(row):
    if row['Date_received'] == 'null':
        return -1
    if row['Date'] != 'null':
        td = pd.to_datetime(row['Date'], format='%Y%m%d') - pd.to_datetime(row['Date_received'], format='%Y%m%d')
        if td <= pd.Timedelta(15, 'D'):
            return 1
    return 0

dfoff['label'] = dfoff.apply(label, axis=1)

print(dfoff['label'].value_counts())

dfoff.head(5)

"""## 优化模型

### 特征提取

通过客户和商户以前的买卖情况，提取各自或者交叉的特征。这里使用20160101到20160515之间的数据提取特征，20160516-20160615的数据作为训练集（划分训练集和验证集）。
"""

# 提取20160101-20160515之间数据的特征
feature = dfoff[(dfoff['Date'] < '20160516') | ((dfoff['Date'] == 'null') & (dfoff['Date_received'] < '20160516'))].copy()
# 将20160516-20160615的数据作为训练集
data = dfoff[(dfoff['Date_received'] >= '20160516') & (dfoff['Date_received'] <= '20160615')].copy()
print(data['label'].value_counts())

fdf = feature.copy()

"""#### 用户 User 特征

u：用户统计
"""

# key of user
u = fdf[['User_id']].copy().drop_duplicates()

"""u1:用户接收到优惠券的数量"""

# u_coupon_count : num of coupon received by user
u1 = fdf[fdf['Date_received'] != 'null'][['User_id']].copy()
u1['u_coupon_count'] = 1
u1 = u1.groupby(['User_id'], as_index = False).count()
u1.head()

"""u2：用户购买的次数"""

# u_buy_count : times of user buy offline (with or without coupon)
u2 = fdf[fdf['Date'] != 'null'][['User_id']].copy()
u2['u_buy_count'] = 1
u2 = u2.groupby(['User_id'], as_index = False).count()
u2.head()

"""u3：用户使用优惠券购买的次数"""

# u_buy_with_coupon : times of user buy offline (with coupon)
u3 = fdf[((fdf['Date'] != 'null') & (fdf['Date_received'] != 'null'))][['User_id']].copy()
u3['u_buy_with_coupon'] = 1
u3 = u3.groupby(['User_id'], as_index = False).count()
u3.head()

"""u4：用户购买的商家个数"""

# u_merchant_count : num of merchant user bought from
u4 = fdf[fdf['Date'] != 'null'][['User_id', 'Merchant_id']].copy()
u4.drop_duplicates(inplace = True)
u4 = u4.groupby(['User_id'], as_index = False).count()
u4.rename(columns = {'Merchant_id':'u_merchant_count'}, inplace = True)
u4.head()

"""u5：用户使用优惠券购买商品距离商店的最小距离

u6：用户使用优惠券购买商品距离商店的最大距离

u7：用户使用优惠券购买商品距离商店的平均距离

u8：用户使用优惠券购买商品距离商店的中位数距离
"""

# u_min_distance
utmp = fdf[(fdf['Date'] != 'null') & (fdf['Date_received'] != 'null')][['User_id', 'distance']].copy()
utmp.replace(-1, np.nan, inplace = True)
u5 = utmp.groupby(['User_id'], as_index = False).min()
u5.rename(columns = {'distance':'u_min_distance'}, inplace = True)
u6 = utmp.groupby(['User_id'], as_index = False).max()
u6.rename(columns = {'distance':'u_max_distance'}, inplace = True)
u7 = utmp.groupby(['User_id'], as_index = False).mean()
u7.rename(columns = {'distance':'u_mean_distance'}, inplace = True)
u8 = utmp.groupby(['User_id'], as_index = False).median()
u8.rename(columns = {'distance':'u_median_distance'}, inplace = True)
u8.head()

"""根据 User_id，将 u1,u2,u3,u4,u5,u6,u7,u8 整合成 user_feature"""

# merge all the features on key User_id
# 进行左表连接
user_feature = pd.merge(u, u1, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u2, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u3, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u4, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u5, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u6, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u7, on = 'User_id', how = 'left')
user_feature = pd.merge(user_feature, u8, on = 'User_id', how = 'left')

"""u_use_coupon_rate：对于用户来说，接收到的优惠券使用率

u_buy_with_coupon_rate：用户所有购买行为中使用优惠券占的比例
"""

# calculate rate
user_feature['u_use_coupon_rate'] = user_feature['u_buy_with_coupon'].astype('float')/user_feature['u_coupon_count'].astype('float')
user_feature['u_buy_with_coupon_rate'] = user_feature['u_buy_with_coupon'].astype('float')/user_feature['u_buy_count'].astype('float')
user_feature = user_feature.fillna(0)
user_feature.head()

"""#### 商户 Merchant 特征

m：商户统计
"""

# key of merchant
m = fdf[['Merchant_id']].copy().drop_duplicates()

"""m1：每个商户发放的优惠券数量"""

# m_coupon_count : num of coupon from merchant
m1 = fdf[fdf['Date_received'] != 'null'][['Merchant_id']].copy()
m1['m_coupon_count'] = 1
m1 = m1.groupby(['Merchant_id'], as_index = False).count()
m1.head()

"""m2：商户销售的次数（不考虑是否使用优惠券）"""

# m_sale_count : num of sale from merchant (with or without coupon)
m2 = fdf[fdf['Date'] != 'null'][['Merchant_id']].copy()
m2['m_sale_count'] = 1
m2 = m2.groupby(['Merchant_id'], as_index = False).count()
m2.head()

"""m3：商户使用优惠券销售的次数"""

# m_sale_with_coupon : num of sale from merchant with coupon usage
m3 = fdf[(fdf['Date'] != 'null') & (fdf['Date_received'] != 'null')][['Merchant_id']].copy()
m3['m_sale_with_coupon'] = 1
m3 = m3.groupby(['Merchant_id'], as_index = False).count()
m3.head()

"""m4：商家销售的用户个数"""

# u_merchant_count : num of merchant user bought from
m4 = fdf[fdf['Date'] != 'null'][['User_id', 'Merchant_id']].copy()
m4.drop_duplicates(inplace = True)
m4 = m4.groupby(['Merchant_id'], as_index = False).count()
m4.rename(columns = {'User_id':'m_user_count'}, inplace = True)
m4.head()

"""m5：商户使用优惠券销售商品距离用户的最小距离

m6：商户使用优惠券销售商品距离用户的最大距离

m7：商户使用优惠券销售商品距离用户的平均距离

m8：商户使用优惠券销售商品距离用户的中位数距离
"""

# m_min_distance
mtmp = fdf[(fdf['Date'] != 'null') & (fdf['Date_received'] != 'null')][['Merchant_id', 'distance']].copy()
mtmp.replace(-1, np.nan, inplace = True)
m5 = mtmp.groupby(['Merchant_id'], as_index = False).min()
m5.rename(columns = {'distance':'m_min_distance'}, inplace = True)
m6 = mtmp.groupby(['Merchant_id'], as_index = False).max()
m6.rename(columns = {'distance':'m_max_distance'}, inplace = True)
m7 = mtmp.groupby(['Merchant_id'], as_index = False).mean()
m7.rename(columns = {'distance':'m_mean_distance'}, inplace = True)
m8 = mtmp.groupby(['Merchant_id'], as_index = False).median()
m8.rename(columns = {'distance':'m_median_distance'}, inplace = True)
m8.head()

"""根据 Merchant_id，将 m1,m2,m3,m4,m5,m6,m7,m8 整合成 merchant_feature"""

merchant_feature = pd.merge(m, m1, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m2, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m3, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m4, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m5, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m6, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m7, on = 'Merchant_id', how = 'left')
merchant_feature = pd.merge(merchant_feature, m8, on = 'Merchant_id', how = 'left')
merchant_feature = merchant_feature.fillna(0)
merchant_feature.head()

"""m_coupon_use_rate： 对于商家来说，发放的优惠卷使用率

m_sale_with_coupon_rate：商家所有销售行为中使用优惠卷占的比例
"""

merchant_feature['m_coupon_use_rate'] = merchant_feature['m_sale_with_coupon'].astype('float')/merchant_feature['m_coupon_count'].astype('float')
merchant_feature['m_sale_with_coupon_rate'] = merchant_feature['m_sale_with_coupon'].astype('float')/merchant_feature['m_sale_count'].astype('float')
merchant_feature = merchant_feature.fillna(0)
merchant_feature.head()

"""#### 用户和商户 User & Merchant 交叉特征

um1：用户和商户对统计
"""

# key of user and merchant
um = fdf[['User_id', 'Merchant_id']].copy().drop_duplicates()

um1 = fdf[['User_id', 'Merchant_id']].copy()
um1['um_count'] = 1
um1 = um1.groupby(['User_id', 'Merchant_id'], as_index = False).count()
um1.head()

"""um2：每个用户商户对交易统计"""

um2 = fdf[fdf['Date'] != 'null'][['User_id', 'Merchant_id']].copy()
um2['um_buy_count'] = 1
um2 = um2.groupby(['User_id', 'Merchant_id'], as_index = False).count()
um2.head()

"""um3：每个用户商户对发放优惠券的统计"""

um3 = fdf[fdf['Date_received'] != 'null'][['User_id', 'Merchant_id']].copy()
um3['um_coupon_count'] = 1
um3 = um3.groupby(['User_id', 'Merchant_id'], as_index = False).count()
um3.head()

"""um4：每个用户商户对使用优惠卷的交易行为的统计"""

um4 = fdf[(fdf['Date_received'] != 'null') & (fdf['Date'] != 'null')][['User_id', 'Merchant_id']].copy()
um4['um_buy_with_coupon'] = 1
um4 = um4.groupby(['User_id', 'Merchant_id'], as_index = False).count()
um4.head()

"""根据 User_id 和 Merchant_id，将 um1,um2,um3,um4 整合成 user_merchant_feature"""

# merge all user merchant 
user_merchant_feature = pd.merge(um, um1, on = ['User_id','Merchant_id'], how = 'left')
user_merchant_feature = pd.merge(user_merchant_feature, um2, on = ['User_id','Merchant_id'], how = 'left')
user_merchant_feature = pd.merge(user_merchant_feature, um3, on = ['User_id','Merchant_id'], how = 'left')
user_merchant_feature = pd.merge(user_merchant_feature, um4, on = ['User_id','Merchant_id'], how = 'left')
user_merchant_feature = user_merchant_feature.fillna(0)

"""um_buy_rate：每个用户商户对交易行为占所有用户商户对的比例

um_coupon_use_rate：使用优惠卷的交易行为占所有用户商户对发放优惠卷的比例

um_buy_with_coupon_rate：使用优惠卷的交易行为占所有用户商户对交易行为的比例
"""

user_merchant_feature['um_buy_rate'] = user_merchant_feature['um_buy_count'].astype('float')/user_merchant_feature['um_count'].astype('float')
user_merchant_feature['um_coupon_use_rate'] = user_merchant_feature['um_buy_with_coupon'].astype('float')/user_merchant_feature['um_coupon_count'].astype('float')
user_merchant_feature['um_buy_with_coupon_rate'] = user_merchant_feature['um_buy_with_coupon'].astype('float')/user_merchant_feature['um_buy_count'].astype('float')
user_merchant_feature = user_merchant_feature.fillna(0)
user_merchant_feature.head()

"""#### 将 user_feature, merchant_feature, user_merchant_feature 放入训练集和测试集中"""

# add user_feature, merchant_feature, user_merchant_feature to train data 
data2 = pd.merge(data, user_feature, on = 'User_id', how = 'left').fillna(0)
data3 = pd.merge(data2, merchant_feature, on = 'Merchant_id', how = 'left').fillna(0)
data4 = pd.merge(data3, user_merchant_feature, on = ['User_id','Merchant_id'], how = 'left').fillna(0)
train = data4.copy()

# add user_feature, merchant_feature, user_merchant_feature to test data 
data2 = pd.merge(dftest, user_feature, on = 'User_id', how = 'left').fillna(0)
data3 = pd.merge(data2, merchant_feature, on = 'Merchant_id', how = 'left').fillna(0)
data4 = pd.merge(data3, user_merchant_feature, on = ['User_id','Merchant_id'], how = 'left').fillna(0)
test = data4.copy()

train.head()

test.head()

"""### 特征数量"""

# feature
original_feature = ['discount_rate','discount_type','discount_man', 'discount_jian','distance', 'weekday', 'weekday_type'] + weekdaycols
print('共有特征：',len(original_feature),'个')
print(original_feature)

"""#### 所有特征"""

predictors = original_feature + user_feature.columns.tolist()[1:] + \
             merchant_feature.columns.tolist()[1:] + \
             user_merchant_feature.columns.tolist()[2:]
print(len(predictors),predictors)

"""### 划分训练集和验证集"""

trainSub, validSub = train_test_split(train, test_size = 0.1, stratify = train['label'], random_state=100)

"""### 集成模型 LightGBM

#### 训练
"""

model = lgb.LGBMClassifier(
                    learning_rate = 0.01,
                    boosting_type = 'gbdt',
                    objective = 'binary',
                    metric = 'logloss',
                    max_depth = 5,
                    sub_feature = 0.7,
                    num_leaves = 3,
                    colsample_bytree = 0.7,
                    n_estimators = 5000,
                    early_stop = 50,
                    verbose = -1)
model.fit(trainSub[predictors], trainSub['label'])

"""#### 验证

对验证集中每个优惠券预测的结果计算 AUC，再对所有优惠券的 AUC 求平均。计算 AUC 的时候，如果 label 只有一类，就直接跳过，因为 AUC 无法计算。
"""

# valid set performance 
y_valid_pred = model.predict_proba(validSub[predictors])
validSub1 = validSub.copy()
validSub1['pred_prob'] = y_valid_pred[:, 1]
validSub1.head()

"""计算 AUC："""

vg = validSub1.groupby(['Coupon_id'])
aucs = []
for i in vg:
    tmpdf = i[1] 
    if len(tmpdf['label'].unique()) != 2:
        continue
    fpr, tpr, thresholds = roc_curve(tmpdf['label'], tmpdf['pred_prob'], pos_label=1)
    aucs.append(auc(fpr, tpr))
print(np.average(aucs))

"""### 测试并提交成绩"""

# test prediction for submission
y_test_pred = model.predict_proba(test[predictors])
submit = test[['User_id','Coupon_id','Date_received']].copy()
submit['label'] = y_test_pred[:,1]
submit.to_csv('submit2.csv', index=False, header=False)
submit.head()

"""### 老师的模型 GradientBoosting

#### 模型训练
"""

from sklearn.ensemble  import  GradientBoostingClassifier
from sklearn.metrics import  roc_auc_score    #计算AUC的

# features =['discount_rate','distance','User_id','discount_man']  #存储特征的，以后要是多了特征，再增加即可
x = trainSub[predictors]   #特征
y = trainSub['label']    #结果标签,一维序列
#x_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size=0.2,stratify=y) #数据拆分，将训练样本拆分成训练集和验证集

#集成学习梯度提升决策树GradientBoostingClassifier分类模型
model = GradientBoostingClassifier(n_estimators=100,max_depth=3)
model.fit(x,y)    #模型训练

"""#### 模型验证"""

#'''模型验证
model.predict_proba(validSub[predictors])   #预测样本的各类标签（这里是0和1）的概率
y_yu = model.predict_proba(validSub[predictors])[:,1]   #'label'为1的概率！
yauc = roc_auc_score(validSub['label'],y_yu)    # （AUC值）这是验证集上的性能结果
print('（AUC值）这是验证集上的性能结果',yauc)  #0.7562965479066022

"""#### 模型预测"""

#模型预测
X_test = test[predictors]
Y_test = model.predict_proba(X_test)[:, 1]  #'label'为1的概率！
submission = test[['User_id', 'Coupon_id', 'Date_received']].copy()
submission['label'] = Y_test
submission.to_csv('output/submission-teacher12.csv', index=None, header=None)
# 这里生成的文件：submission1.csv 提交到比赛网站即可！
submission.head()